# -*- coding: utf-8 -*-
"""Final Submission Image Classification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hb8B3kS331VEtTE21JSKZACoNZ9lvEBn

## **Final Submission Image Classification**
###### Nama : Zaki Anwar Farizan
###### No. Register : 1494037162101-1245
"""

# Import library tensorflow
import tensorflow as tf
print(tf.__version__)

"""**Import Dictionary**"""

# Commented out IPython magic to ensure Python compatibility.
import os
import tensorflow as tf
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import pathlib
from sklearn import preprocessing
from keras.models import Sequential
from keras.layers import Dense
from google.colab import files
from keras.preprocessing import image
import matplotlib.image as mpimg
# %matplotlib inline

"""**Mengambil Dataset**"""

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download puneet6060/intel-image-classification

! unzip intel-image-classification

base_dir = '/content/seg_train/seg_train'
train_dir = base_dir
validation_dir = base_dir

# Cek Class
os.listdir('/content/seg_train/seg_train')

"""**Membagi Dataset menjadi Train dan Test**"""

# Augmentasi Gambar dengan ImageDataGenerator
from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest',
                    validation_split=0.2)

validation_datagen = ImageDataGenerator(
                    rescale=1./255,
                    validation_split=0.2)

# Train & validation split
train = train_datagen.flow_from_directory(
        train_dir,
        target_size=(150, 150),
        batch_size=32,
        class_mode='categorical',
        subset='training')

validation = validation_datagen.flow_from_directory(
        validation_dir,
        target_size=(150, 150),
        batch_size=32, 
        class_mode='categorical',
        subset='validation')

"""**Pembuatan Model**"""

# Model Sequential
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(6, activation='softmax')
])

model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(learning_rate=0.001),
              metrics=['accuracy'])

model.summary()

# Callback
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.95):
      print("\nAkurasi telah mencapai >95%!")
      self.model.stop_training = True
callbacks = myCallback()

history = model.fit(
      train,
      steps_per_epoch=30,  
      epochs=50,
      validation_data=validation, 
      validation_steps=10,
      callbacks=[callbacks])

accur = history.history['accuracy']
val_accur = history.history['val_accuracy'] 

epochs = range(len(accur))

plt.figure(figsize=(12,8))
plt.plot(epochs, accur, 'r', label='Training accuracy')
plt.plot(epochs, val_accur, 'b', label='Test accuracy')
plt.title('Training and Test accuracy')
plt.legend(loc=0)
plt.show()

loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(accur))

plt.figure(figsize=(12,8))
plt.plot(epochs, loss, 'r', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Test Loss')
plt.title('Training and Test Loss')
plt.legend(loc=0)
plt.show()

"""**Menyimpan ke tf.lite**"""

import pathlib

# Menyimpan model dalam format SavedModel
export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)
 
# Convert SavedModel menjadi intel_image.tflite
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()
 
tflite_model_file = pathlib.Path('intel_image.tflite')
tflite_model_file.write_bytes(tflite_model)

